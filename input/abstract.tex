\vspace*{4cm}
\begin{fullwidth}
\begin{center}
\huge{Abstract}
\end{center}
\thispagestyle{empty}
Recursive partitioning is a popular modeling tool for data analysis. 
Due to the resulting tree structure of the partitioned covariate space, the 
models are easy to interpret. Many of the existing partitioning algorithms suffer from a biased 
variable selection, meaning that variables with more possible values are selected
more frequently. \\
This paper presents the work of \citet{hothorn2006unbiased}, who proposed and implemented an 
partitioning algorithm, which has an unbiased variable selection: conditional inference trees. 
All decisions are formulated as statistical hypotheses and tested with permutation tests. The 
proposed framework covers not only numeric and nominal regression, but arbitrary measurement
scales of response and covariates, like ordinal or censored regression. 
This papers regards the algorithm in detail and illustrates it with two examples. 
Special emphasis is on the used test statistics. 
\end{fullwidth}
